{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "muslim-monte",
   "metadata": {},
   "source": [
    "#  Обучаем Word2Wec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-spider",
   "metadata": {},
   "source": [
    "## Подготовка dataset-а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "similar-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train = pd.read_parquet('data_fusion_train.parquet', engine='pyarrow')\n",
    "train = train[train.category_id == -1].drop_duplicates('item_name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "present-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_names = train['item_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "restricted-fancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/web/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pymorphy2\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "patterns = \"[A-Za-z0-9!#$%&№'()*+,./:;<=>?@[\\]^_`{|}~—\\\"\\-]+\"\n",
    "stopwords_ru = stopwords.words(\"russian\")\n",
    "morph = MorphAnalyzer()\n",
    "def lemmatize(doc):\n",
    "    doc = re.sub(patterns, ' ', doc)\n",
    "    tokens = []\n",
    "    for token in doc.split():\n",
    "        if token and token not in stopwords_ru:\n",
    "            token = token.strip()\n",
    "            token = morph.normal_forms(token)[0]\n",
    "            \n",
    "            tokens.append(token)\n",
    "    if len(tokens) > 2:\n",
    "        return tokens\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-cambridge",
   "metadata": {},
   "source": [
    "## Обрабатываем 1/10 от всех данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "taken-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3107/3107 [1:13:02<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "result = []\n",
    "num_iters = int(len(product_names)/1000)\n",
    "last_iter = 0\n",
    "\n",
    "\n",
    "for i in tqdm(range(num_iters)):\n",
    "    i+=1\n",
    "    if i == num_iters:\n",
    "        result+=product_names[num_iters*1000:].apply(lemmatize).tolist()\n",
    "    else:\n",
    "        result+=product_names[last_iter*1000:i*1000].apply(lemmatize).tolist()\n",
    "    last_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "communist-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[_ for _ in ws if len(_) > 2] for ws in result if ws is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "domestic-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "word_freq = defaultdict(int)\n",
    "for tokens in data:\n",
    "    for token in tokens:\n",
    "        word_freq[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "alone-binding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150971"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vanilla-language",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['далее',\n",
       " 'смотреть',\n",
       " 'таб',\n",
       " 'пиво',\n",
       " 'вес',\n",
       " 'белый',\n",
       " 'печение',\n",
       " 'напиток',\n",
       " 'салат',\n",
       " 'сыр']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-convenience",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ethical-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    min_count=10,\n",
    "    window=2,\n",
    "    size=300,\n",
    "    negative=10,\n",
    "    alpha=0.03,\n",
    "    min_alpha=0.0007,\n",
    "    sample=6e-5,\n",
    "    sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "electrical-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.train(data, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"хлеб\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-moses",
   "metadata": {},
   "source": [
    "## Проверка качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet('data_fusion_train.parquet', engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test.category_id != -1].drop_duplicates('item_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_names = test['item_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = product_names.apply(lemmatize).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_arrs = [[_ for _ in ws if len(_) > 2] if ws is not None else [] for ws in test_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "embendding_len = len(w2v_model.wv.word_vec(\"хлеб\"))\n",
    "embendding_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embenddings = []\n",
    "for words in words_arrs:\n",
    "    element_embenddings = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            element_embenddings.append(w2v_model.wv.word_vec(word))\n",
    "        except KeyError:\n",
    "            pass\n",
    "    if len(element_embenddings) == 0:\n",
    "        test_embenddings.append([0]*embendding_len)\n",
    "    else:\n",
    "        test_embenddings.append(sum(element_embenddings))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_embenddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words_arrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_embenddings\n",
    "labels = test[\"category_id\"].tolist()\n",
    "print(len(data))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-racing",
   "metadata": {},
   "source": [
    "## Оценка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(classifier.predict(data), labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-shadow",
   "metadata": {},
   "source": [
    "## Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "tsne = manifold.TSNE(n_components = 2, init = 'pca', random_state = 0)\n",
    "data_2d_tsne = tsne.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as PLT\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(figsize = (10, 6))\n",
    "pylab.scatter(data_2d_tsne[:, 0], data_2d_tsne[:, 1], c = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-deadline",
   "metadata": {},
   "source": [
    "## Количество нулевых векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for embendding in tqdm(data):\n",
    "    if np.array_equal(embendding, [0]*300):\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count*100/len(data), \"% элементов выборки не обрабатываются моделью\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-underwear",
   "metadata": {},
   "source": [
    "## Примеры необрабатываемых объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for embendding, words_arr, product_name in zip(data, words_arrs, product_names.tolist()):\n",
    "    if np.array_equal(embendding, [0]*300):\n",
    "        print(product_name)\n",
    "#         print(words_arr)\n",
    "        count += 1\n",
    "    if count >= 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-flesh",
   "metadata": {},
   "source": [
    "## Нужно обучать на всей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-owner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-exchange",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
